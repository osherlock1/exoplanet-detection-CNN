{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjya8D5aL9q4AFufTegqvO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osherlock1/exoplanet-detection-CNN/blob/main/lightcurve_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "ck_m9gHLGJDk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nC7cJvyEOpc"
      },
      "outputs": [],
      "source": [
        "!pip install lightkurve"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imports**"
      ],
      "metadata": {
        "id": "XtT-Dm9NGRUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Standard Libaries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "#Handling Fits files\n",
        "from astropy.timeseries import TimeSeries\n",
        "from astropy.time import Time\n",
        "from astropy.io import fits\n",
        "\n",
        "#Google Colab\n",
        "from google.colab import drive\n",
        "\n",
        "#Lightkurve\n",
        "import lightkurve as lk\n",
        "\n",
        "#Pytorch\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from concurrent.futures import ProcessPoolExecutor"
      ],
      "metadata": {
        "id": "2J7a1EJDGIoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Google Drive**"
      ],
      "metadata": {
        "id": "TRYAPcbIGPsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#File path for directory\n",
        "fits_directory = '/content/drive/MyDrive/ELE391_Final_Project/data/Kepler/Kepler_conf'"
      ],
      "metadata": {
        "id": "ODKU1EeKGM4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K2 Processing"
      ],
      "metadata": {
        "id": "Mxt3xSM8HJUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_single_file(fits_file, fits_directory, output_directory, num_bins=200):\n",
        "    \"\"\"\n",
        "    Processes a single .fits file and saves the resulting tensor to the output directory.\n",
        "    \"\"\"\n",
        "    file_path = os.path.join(fits_directory, fits_file)\n",
        "\n",
        "    # Open the FITS file and extract data\n",
        "    with fits.open(file_path) as hdul:\n",
        "        data = hdul[1].data  # Light curve is usually in the second HDU\n",
        "        time = data['T']\n",
        "        flux = data['FCOR']\n",
        "        #quality = data['SAP_QUALITY']\n",
        "\n",
        "\n",
        "\n",
        "    # Remove NaN values\n",
        "    valid = ~np.isnan(time) & ~np.isnan(flux) & np.isfinite(time) & np.isfinite(flux)\n",
        "    time = time[valid]\n",
        "    flux = flux[valid]\n",
        "\n",
        "    # Create lightkurve object\n",
        "    lc = lk.LightCurve(time=time[np.isfinite(time)], flux=flux[np.isfinite(time)])\n",
        "\n",
        "    # Remove outliers\n",
        "    lc_cleaned = lc.remove_outliers(sigma=5)\n",
        "\n",
        "    # Flatten and normalize the light curve\n",
        "    lc_flat = lc_cleaned.flatten().normalize()\n",
        "\n",
        "    # Find best period\n",
        "    periodogram = lc_flat.to_periodogram(method=\"bls\")\n",
        "    best_period = periodogram.period_at_max_power\n",
        "\n",
        "    # Fold the light curve\n",
        "    folded_lc = lc_flat.fold(period=best_period, normalize_phase=True)\n",
        "\n",
        "    phase = folded_lc.phase.value + 0.5\n",
        "    flux = folded_lc.flux.value\n",
        "\n",
        "    # Bin the folded light curve\n",
        "    bin_edges = np.linspace(0, 1, num_bins + 1)\n",
        "    bin_indices = np.digitize(phase, bins=bin_edges) - 1\n",
        "\n",
        "    binned_flux = np.array([\n",
        "      np.mean(flux[bin_indices == i]) if np.any(bin_indices == i) else np.nan\n",
        "      for i in range(num_bins)\n",
        "    ])\n",
        "\n",
        "\n",
        "    # Interpolate NaN values\n",
        "    nans = np.isnan(binned_flux)\n",
        "    x = np.arange(len(binned_flux))\n",
        "    binned_flux[nans] = np.interp(x[nans], x[~nans], binned_flux[~nans])\n",
        "\n",
        "\n",
        "    if np.std(binned_flux) > 0:\n",
        "      binned_flux = (binned_flux - np.mean(binned_flux)) / np.std(binned_flux)\n",
        "\n",
        "    # Convert to PyTorch tensor and save\n",
        "    binned_tensor = torch.tensor(binned_flux, dtype=torch.float32)\n",
        "    output_path = os.path.join(output_directory, f\"{os.path.splitext(fits_file)[0]}.pt\")\n",
        "    torch.save(binned_tensor, output_path)\n",
        "\n",
        "    print(f\"Processed and saved: {fits_file} -> {output_path}\")\n",
        "\n",
        "def process_lightcurves_parallel(fits_directory, output_directory, num_bins=200):\n",
        "    \"\"\"\n",
        "    Processes all .fits files in a directory in parallel.\n",
        "    \"\"\"\n",
        "    # List all .fits files in the directory\n",
        "    fits_files = [f for f in os.listdir(fits_directory) if f.endswith('.fits')]\n",
        "\n",
        "    # Process files in parallel\n",
        "    with ProcessPoolExecutor() as executor:\n",
        "        executor.map(\n",
        "            lambda fits_file: process_single_file(\n",
        "                fits_file, fits_directory, output_directory, num_bins\n",
        "            ),\n",
        "            fits_files\n",
        "        )\n",
        "\n",
        "    print(\"All files processed.\")\n"
      ],
      "metadata": {
        "id": "K4nKCbMkGTkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fits_directory = '/content/drive/MyDrive/ELE391_Final_Project/data/K2/K2_confirmed_names'\n",
        "output_directory = '/content/drive/MyDrive/ELE391_Final_Project/data_v2/K2_v2/K2_conf_200'\n",
        "\n",
        "fits_files = [f for f in os.listdir(fits_directory) if f.lower().endswith('.fits')]\n",
        "print(f\"Found {len(fits_files)} files to process.\")\n",
        "\n",
        "def debug_wrapper(fits_file):\n",
        "    print(f\"Passing to process_single_file: {fits_file}\")\n",
        "    process_single_file(fits_file, fits_directory, output_directory, num_bins=200)\n",
        "\n",
        "with ProcessPoolExecutor() as executor:\n",
        "    executor.map(debug_wrapper, fits_files)"
      ],
      "metadata": {
        "id": "p6cS5UzzG2f7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting Binned Light Curves"
      ],
      "metadata": {
        "id": "VfQgdMhqHM4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_binned_lightcurve(pt_file, num_bins=200):\n",
        "    \"\"\"\n",
        "    Read a binned light curve from a .pt file and plot it.\n",
        "    Args:\n",
        "        pt_file (str): Path to the .pt file containing the binned light curve.\n",
        "        num_bins (int): Number of bins used in the binned light curve.\n",
        "    \"\"\"\n",
        "    # Load the binned flux tensor\n",
        "    binned_flux = torch.load(pt_file)\n",
        "\n",
        "    # Check if the file is a PyTorch tensor\n",
        "    if not isinstance(binned_flux, torch.Tensor):\n",
        "        raise ValueError(\"The loaded file does not contain a PyTorch tensor.\")\n",
        "\n",
        "    # Generate bin midpoints for the phase\n",
        "    bin_edges = np.linspace(0, 1, num_bins + 1)\n",
        "    binned_phase = (bin_edges[:-1] + bin_edges[1:]) / 2  # Midpoints of the bins\n",
        "\n",
        "    # Convert tensor to NumPy for plotting\n",
        "    binned_flux = binned_flux.numpy()\n",
        "\n",
        "    # Plot the binned light curve\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(binned_phase, binned_flux, '-o', label=f'Binned Light Curve: {os.path.basename(pt_file)}', color='blue')\n",
        "    plt.xlabel(\"Phase\")\n",
        "    plt.ylabel(\"Flux\")\n",
        "    plt.title(f\"Binned Light Curve: {os.path.basename(pt_file)}\")\n",
        "    plt.grid(alpha=0.5)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_all_lightcurves_in_dir(directory, num_bins=200):\n",
        "    \"\"\"\n",
        "    Find all .pt files in the directory and plot their light curves.\n",
        "    Args:\n",
        "        directory (str): Path to the directory containing .pt files.\n",
        "        num_bins (int): Number of bins used in the binned light curves.\n",
        "    \"\"\"\n",
        "    # List all .pt files in the directory\n",
        "    pt_files = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith('.pt')]\n",
        "\n",
        "    # Check if there are any .pt files\n",
        "    if not pt_files:\n",
        "        print(\"No .pt files found in the directory.\")\n",
        "        return\n",
        "\n",
        "    # Plot each .pt file\n",
        "    for pt_file in pt_files:\n",
        "        try:\n",
        "            print(f\"Plotting: {pt_file}\")\n",
        "            plot_binned_lightcurve(pt_file, num_bins)\n",
        "        except Exception as e:\n",
        "            print(f\"Error plotting {pt_file}: {e}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_k_Ik47GHMcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory containing .pt files\n",
        "directory = '/content/drive/MyDrive/ELE391_Final_Project/data_v4/K2_fp_pt'\n",
        "\n",
        "# Plot all light curves in the directory\n",
        "plot_all_lightcurves_in_dir(directory, num_bins=400)"
      ],
      "metadata": {
        "id": "ksdkQ3YuHRQM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}